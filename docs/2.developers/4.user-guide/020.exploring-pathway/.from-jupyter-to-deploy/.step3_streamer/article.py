# ---
# title: "Part 3: Kafka data streamer"
# description: ''
# notebook_export_path: projects/from_jupyter_to_deploy/part3_kafka_data_streamer.ipynb
# author: pathway
# article:
#   date: '2023-11-29'
#   thumbnail: ''
#   tags: []
# jupyter:
#   jupytext:
#     formats: py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.15.2
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# %% [markdown]
# # Part 3: Kafka integration and alerts forwarding (Producer)
#
# This notebook is a helper notebook for the third part of the tutorial [From interactive data exploration to deployment](https://pathway.com/developers/user-guide/exploring-pathway/from-jupyter-to-deploy/#part-3-kafka-integration-and-alerts-forwarding).

# %%
# Download CSV file
# !wget -nc https://gist.githubusercontent.com/janchorowski/e351af72ecd8d206a34763a428826ab7/raw/ticker.csv

# %% [markdown]
# ## Writing messages to Kafka

# %%
import pathway as pw

fname = "ticker.csv"
schema = pw.schema_from_csv(fname)


# %%
print(schema.generate_class(class_name="DataSchema"))


# %%
# The schema definition is autogenerated
class DataSchema(pw.Schema):
    ticker: str
    open: float
    high: float
    low: float
    close: float
    volume: float
    vwap: float
    t: int
    transactions: int
    otc: str


data = pw.demo.replay_csv(fname, schema=DataSchema, input_rate=1000)

# %%
# TODO: please set appropriaye values for KAFKA_ENDPOINT, KAFKA_USERNAME, and KAFKA_PASSWORD
rdkafka_producer_settings = {
    "bootstrap.servers": "KAFKA_ENDPOINT:9092",
    "security.protocol": "sasl_ssl",
    "sasl.mechanism": "SCRAM-SHA-256",
    "sasl.username": "KAFKA_USERNAME",
    "sasl.password": "KAFKA_PASSWORD",
}

pw.io.kafka.write(data, rdkafka_producer_settings, topic_name="ticker")

# %%
# _MD_SHOW_pw.run()
