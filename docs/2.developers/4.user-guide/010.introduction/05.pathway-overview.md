---
title: Pathway Overview
description: 'Quick introduction to Pathway operators.'
---

# Quick Overview of Pathway
This page is a summary of what you need to know about to start programming with Pathway.
If you want to learn more about the core concepts of Pathway, you can read the [dedicated article](/developers/user-guide/introduction/concepts).

## Getting started
You can install Pathway with a simple pip command:
```
pip install pathway
```
Once installed, you can import Pathway as follows:
```python
import pathway as pw
```

## Table
In Pathway, data is modeled using [tables](/developers/user-guide/introduction/concepts#tables-dynamic-content-with-static-schema).
Pathway tables are similar to classical relational tables, organized into columns and rows.
As Pathway handles potentially infinite and ever-changing streaming data, the number of rows and the content changes with time as new data comes into the system.

### Types and Schema

In Pathway, columns can contain the following basic [data types](/developers/user-guide/connect/datatypes): `bool`, `str`, `bytes`, `int`, and `float`.
Pathway also supports more complex data types, such as the `Optional` data type or temporal data types (`datetime.datetime`).

The structure of each table is defined by a [schema](/developers/user-guide/connect/schema):

```python
class InputSchema(pw.Schema):
    colA: int
    colB: float
    colC: str
```

### Connectors
To create a table from a data source and output data out of Pathway, you need to use a connector.
Here is a small sample of Pathway input and output connectors.

**Input connectors**:
| Connectors                     |  Example                                                                                |
|--------------------------------|-----------------------------------------------------------------------------------------|
| CSV connector                  | `pw.io.csv.read('./data/', schema=InputSchema)`                                         |
| Kafka connector                | `pw.io.kafka.read(rdkafka_settings, topic="example", schema=InputSchema, format="csv")` |
| SQLite connector               | `pw.io.sqlite.read('./data_path/', table_name, schema=InputSchema)`                     |
| Google Drive connector         | `pw.io.gdrive.read(object_id='***', service_user_credentials_file="credentials.json")`  |

**Output connectors**:
| Connectors                     |  Example                                                                                |
|--------------------------------|-----------------------------------------------------------------------------------------|
| CSV connector                  | `pw.io.csv.write(table, './output/')`                                                   |
| Kafka output connector         | `pw.io.kafka.write(table, rdkafka_settings, topic_name="example", format="json")`       |
| PostgreSQL connector           | `pw.io.postgres.write(table, output_postgres_settings, "sum_table")`                    |
| Google PubSub connector        | `pw.io.pubsub.write(table, publisher, project_id, topic_id)`                            |

Pathway comes with many more connectors, including an [Airbyte connector](/developers/api-docs/pathway-io/airbyte) that allows you to connect to 300+ sources.
You can find the list of available connectors on our [connector page](/developers/user-guide/connect/pathway-connectors).

## Transformations
You can process the data using [Pathway transformations](/developers/user-guide/introduction/concepts#processing-the-data-with-transformations):

| Category                       | Operations                       | Example                                           |
|--------------------------------|----------------------------------|---------------------------------------------------|
| Selection of a column          | select and dot/bracket notation  | `t.select(t.colA, t['colB'], pw.this.colC)`       |
| Selection of all columns       | select and star notation         | `t.select(*pw.this)`                              |
| Removing columns               | without and dot/bracket notation   | `t.without(t.colA, t.colB)`                       |
| Arithmetic operations          | +, -, *, /, //, %, **              | `t.select(new_col = t.colA + t.colB)`             |
| Comparison operations          | ==, !=, <, <=, >, >=               | `t.select(new_col = t.colA <= t.colB)`            |
| Boolean operations             | & (AND), \| (OR), ~ (NOT), ^ (XOR) | `t.select(new_col = t.colA & (t.colB < 3))`       |
| Filtering                      | filter                             | `t.filter(pw.this.column > value)`                |
| Reindexing                     | with_id_from                       | `t.with_id_from(t_new_ids.new_id_source)`         |
| [Reference Indexing](/developers/user-guide/data-transformation/indexing-grouped-tables)       | ix_ref                           | `t_selected_ids.select(selected=t.ix_ref(column).name)` |
| [Flattening a column](/developers/api-docs/pathway-table#pathway.Table.flatten)              | flatten                            | `t.flatten(pw.this.column)`                |
| [Group-by and Aggregation](/developers/user-guide/data-transformation/groupby-reduce-manual) | groupby, reduce                  | `t.groupby(pw.this.column).reduce(sum=pw.reducers.sum(pw.this.column))` |
| Union and Concatenation  | union (+, +=), concat_reindex    | `t_union = t1 + t2`                                |
| [Join Operations](/developers/user-guide/data-transformation/join-manual)          | join (inner, outer, left, right) | `t1.join(t2, pw.left.column == pw.right.column).select(...)` |
| Adding/Renaming Columns  | select (add), rename             | `t.select(*pw.this, new_col=t.old_col)`, `t.rename(new_col=pw.this.old_col)` |
| Updating Cell Values     | update_cells, <<                 | `t.update_cells(t_new)`                            |
| Applying a function      | pw.apply                         | `t.select(new_col=pw.apply(func, pw.this.colA))` |
| [Iterative computations](/developers/user-guide/data-transformation/iterate)   | pw.iterate                       | `pw.iterate(iteration_method, table=t)` |
| [Performing a SQL command](/developers/api-docs/sql-api) | pw.sql                           | `pw.sql(query, tab=t)` |

You can find examples of Pathway basic operations in [our guide](/developers/user-guide/data-transformation/table-operations).


## Temporal transformations

| Category                   | Operations                                    | Example                                           |
|----------------------------|-----------------------------------------------|---------------------------------------------------|
| [Windowing operations](/developers/user-guide/temporal-data/windows-manual)       | windowby (sliding, tumbling, session) reduce  | `t.windowby(t.time, window=pw.temporal.tumbling(duration=...),...).reduce(...)` |
| [ASOF now join](/developers/user-guide/data-transformation/indexes-in-pathway/#asof-now-join)     | asof_now_join                           | `t1.asof_now_join(t2, t1.t, t2.t, t1.name==t2.name, how=..., direction=...).select(...)`      |
| [Interval join](/developers/user-guide/temporal-data/interval-join)              | interval_join (outer, left, right)  | `t1.interval_join(t2, t1.t, t2.t, pw.temporal.interval(...), t1.col==t2.col).select(...)` |
| [Window join](/developers/user-guide/temporal-data/window-join)                | interval_join (outer, left, right)  | `t1.window_join(t2, t1.t, t2.t, pw.temporal.sliding(...), t1.col==t2.col).select(...)` |

The [behavior](/developers/user-guide/temporal-data/behaviors) of temporal operations determines the tradeoff between accuracy, latency, and memory consumption.
You can [control the behavior](/developers/user-guide/temporal-data/windows_with_behaviors) of temporal operations to adapt the tradeoff to your application.

## Running the pipeline

Once your pipeline is ready, with both connectors and transformations, you can run the computation with the command run:
```python
pw.run()
```
Pathway listens to the data sources for new updates until the process is terminated: **the computation runs forever until the process gets killed**.
[**This is the normal behavior of Pathway**](/developers/user-guide/introduction/concepts#running-the-computation-with-the-rust-engine).

## LLM tooling
Pathway comes with an LLM xpack that provides you all the tools you need to use Large Language Models in Pathway.
If you are interested, you can learn more [here](/developers/user-guide/llm-xpack/overview).
