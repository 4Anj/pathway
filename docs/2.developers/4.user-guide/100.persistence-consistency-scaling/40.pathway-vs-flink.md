---
title: Pathway vs Flink
description: 'This page compares Pathway and Flink'
toc: false
---

# Comparison with Flink

Pathway is a Python framework with a unified engine for batch and streaming data processing.
Why should you choose Pathway instead of any other existing streaming engines, such as Apache Flink?

To assist you in your choice, here is a blueprint of Pathway features is provided below, together with a comparison to Apache Flink.

<table>
<thead>
<tr>
<th>Feature
<th>Pathway
<th>Apache Flink
</tr>
</thead>
<tbody>
<tr>
<th colspan="3">General</td>
</tr>
<tr>
<td>Processing Type</td>
<td>Stream and batch (with the same engine).<br>Guarantees of same results returned whether running in batch or streaming.<br>Capacity for asynchronous stream processing and API integration.</td>
<td>Stream and batch (with different engines).</td>
</tr>
<tr>
<td>Programming language APIs</td>
<td>Python, SQL</td>
<td>JVM (Java, Kotlin, Scala), SQL, Python</td>
</tr>
<tr>
<td>Programming API</td>
<td>Table API</td>
<td>DataStream API and Table API, with partial compatibility</td>
</tr>
<tr>
<td>Software integration ecosystems/plugin formats.</td>
<td>Python,<br>C binary interface (C, C++, Rust),<br>REST API.</td>
<td>JVM</td>
</tr>
</tbody>
<tbody>
<tr>
<th colspan="3">Ease of development</td>
</tr>
<tr>
<td>How to QuickStart</td>
<td>Get Python.<br>Do `pip install pathway`.<br>Run directly.</td>
<td>Get Java.<br>Download and unpack Flink packages.<br>Start a local Flink Cluster with `./bin/start-local.sh`.<br>Use netcat to start a local server.<br>Submit your program to the server for running.</td>
</tr>
<tr>
<td>Running local experiments with data</td>
<td>Use Pathway locally in VS Code, Jupyter, etc.</td>
<td>Based on local Flink clusters</td>
</tr>
<tr>
<td>CI/CD and Testing</td>
<td>Usual CI/CD setup for Python (use GitHub Actions, Jenkins etc.)<br>Simulated stream library for easy stream testing from file sources.</td>
<td>Based on local Flink cluster integration into CI/CD pipelines</td>
</tr>
<tr>
<td>Interactive work possible?</td>
<td>Yes, data manipulation routines can be interactively created in notebooks and the Python REPL</td>
<td>Compilation is necessary, breaking data-scientist's flow of work</td>
</tr>
</tbody>
<tbody>
<tr>
<th colspan="3">Performance</th>
</tr>
<tr>
<td>Scalability</td>
<td>Horizontal* and vertical scaling.<br>Scales to thousands of cores and terabytes of application state.<br>Standard and custom libraries (including ML library) are scalable.</td>
<td>Horizontal and vertical scaling.<br>Scales to thousands of cores and terabytes of application state.<br>Most standard libraries (including ML library) do not parallelize in streaming mode.</td>
</tr>
<tr>
<td>Performance for basic tasks (groupby, filter, single join)</td>
<td>Delivers high throughput and low latency.</td>
<td>Slower than Pathway in benchmarks.</td>
</tr>
<tr>
<td>Transformation chain length in batch computing</td>
<td>1000+ transformations possible, iteration loops possible</td>
<td>Max. 40 transformations recommended (in both batch and streaming mode).</td>
</tr>
<tr>
<td>Fast advanced data transformation (iterative graph algorithms, machine learning)</td>
<td>In batch and streaming mode.</td>
<td>No; restricted subset possible in batch mode only.</td>
</tr>
<tr>
<td>Parameter tuning required</td>
<td>Instance sizing only.<br>Possibility to set window cut-off times for late data.</td>
<td>Considerable tuning required for streaming jobs.</td>
</tr>
</tbody>
<tbody>
<tr>
<th colspan="3">Architecture and deployment</th>
</tr>
<tr>
<td>Distributed Deployment (for Kubernetes or bare metal clusters)</td>
<td>Pool of identical workers (pods).*<br>Sharded by data.</td>
<td>Includes a JobManager and pool of TaskManagers.<br>Work divided by operation and/or sharded by data.</td>
</tr>
<tr>
<td>Dataflow handling and communication</td>
<td>Entire dataflow handled by each worker on a data shard, with asynchronous communication when data needs routing between workers.<br>Backpressure built-in.</td>
<td>Multiple communication mechanisms depending on configuration.<br>Backpressure handling mechanisms needed across multiple workers.</td>
</tr>
<tr>
<td>Internal Incremental Processing Paradigm</td>
<td>Commutative<br>(based on record count deltas)</td>
<td>Idempotent<br>(upsert)</td>
</tr>
<tr>
<td>Primary data structure for state</td>
<td>Multi-temporal Log-structured merge-tree (shared arrangements).<br>In-memory state.</td>
<td>Log-structured merge-tree.<br>In-memory state.</td>
</tr>
<tr>
<td>State Management</td>
<td>Integrated with computation.<br>Cold-storage persistence layer optional.<br>Low checkpointing overhead.*</td>
<td>Integrated with computation.<br>Cold-storage persistence layer optional.</td>
</tr>
<tr>
<td>Semantics of stream connectors</td>
<td>Insert / Upsert</td>
<td>Insert / Upsert</td>
</tr>
<tr>
<td>Message Delivery Guarantees</td>
<td>Ensures exactly-once delivery guarantees for state and outputs (if enabled)</td>
<td>Ensures exactly-once delivery guarantees for state and outputs (if enabled)</td>
</tr>
<tr>
<td>Consistency</td>
<td>Consistent, with exact progress tracking. Outputs reflect all data contained in a prefix of the source streams. All messages are atomically processed, if downstream systems have a notion of transaction no intermediate states are sent out of the system.</td>
<td>Eventually consistent, with approximate progress tracking using watermarks. Outputs may reflect partially processed messages and transient inconsistent outputs may be sent out of the system.</td>
</tr>
<tr>
<td>Processing out-of-order data</td>
<td>Supported by default.<br>Outputs of built-in operations do not depend on data arrival order (unless they are configured to ignore very late data).<br>Event times used for windowing and temporal operations.</td>
<td>Supported or fragile, depending on the scenario. Event time processing supported in addition to arrival time and approximate watermarking semantics.</td>
</tr>
<tr>
<td>Fault tolerance</td>
<td>Rewind-to-snapshot.<br>Partial failover handled transparently in hot replica setups.*</td>
<td>Rewind-to-snapshot.<br>Support for partial failover present or not depending on scheduler.</td>
</tr>
<tr>
<td>Monitoring system</td>
<td>Prometheus-compatible endpoint on each pod</td>
<td></td>
</tr>
<tr>
<td>Logging system</td>
<td>Integrates with Docker and Kubernetes Container logs</td>
<td></td>
</tr>
</tbody>
<tbody>
<tr>
<th colspan="3">Machine Learning support</th>
</tr>
<tr>
<td>Language of ML library implementation</td>
<td>Python / Pathway</td>
<td>JVM / Flink</td>
</tr>
<tr>
<td>Parallelism support by ML libraries</td>
<td>ML libraries scale vertically and horizontally</td>
<td>Most ML libraries are not built for parallelization</td>
</tr>
<tr>
<td>Supported modes of ML inference</td>
<td>CPU Inference on worker nodes.<br>Asynchronous Inference (GPU/CPU).<br>Alerting of results updates after model change.</td>
<td>CPU Inference on worker nodes.</td>
</tr>
<tr>
<td>Supported modes of ML learning</td>
<td>Add data to the training set.<br>Update or delete data in the training set.<br>Revise past classification decisions.</td>
<td>Add data to the training set.</td>
</tr>
<tr>
<td>Representative real-time Machine Learning libraries.</td>
<td>Classification (including kNN), Clusterings, graph clustering, graph algorithms, vector indexes, signal processing.<br>Geospatial libraries, spatio-temporal data, GPS and trajectories.*<br>Possibility to integrate external Python real-time ML libraries.</td>
<td>Classification (including kNN), Clusterings, vector indexes.</td>
</tr>
<tr>
<td>Support for iterative algorithms (iterate until convergence, gradient descent, etc.)</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>API Integration with external Machine Learning models and LLMs</td>
<td>Yes</td>
<td>No / fragile</td>
</tr>
<tr>
<td>Typical Analytics and Machine Learning use cases</td>
<td>Data fusion<br>Monitoring and alerting (rule-based or ML-powered)<br>IoT and logs data observability (rule-based or ML-powered)<br>Trajectory mining*<br>Graph learning<br>Recommender systems<br>Ontologies and dynamic knowledge graphs.<br>Real-time data indexing (vector indexes).<br>LLM-enabled data pipelines and RAG services.<br>Low-latency feature stores.</td>
<td>Monitoring and alerting (rule-based)<br>IoT and logs data observability (rule-based)</td>
</tr>
</tbody>
<tbody>
<tr>
<th colspan="3">API and HTTP microservices</th>
</tr>
<tr>
<td>REST/HTTP API integration</td>
<td>Non-blocking (Asynchronous API calls) supported in addition to Synchronous calls.</td>
<td>Blocking (Synchronous calls)</td>
</tr>
<tr>
<td>Acting as microservice host</td>
<td>Provides API endpoint mechanism for user queries.<br>Supports registered queries (API session mechanism, alerting).</td>
<td>No</td>
</tr>
<tr>
<td>Use as low-latency feature store</td>
<td>Yes, standalone. From 1ms latency.</td>
<td>Possible in combination with Key-value store like Redis. From 5ms latency.<br>Requires manual versioning/consistency checks.</td>
</tr>
</tbody>
</table>

\* Features only available in the enterprise version of Pathway. See also [Feature comparison](/features).
